{
    "llama2": {
        "name": "llama2",
        "description": "Llama 2 is a state-of-the-art large language model.",
        "context_length": 4096,
        "memory_required": 10.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "repeat_penalty": 1.1
        }
    },
    "mistral": {
        "name": "mistral",
        "description": "Mistral is an efficient and powerful language model.",
        "context_length": 8192,
        "memory_required": 4.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "repeat_penalty": 1.1
        }
    },
    "mistral:latest": {
        "name": "mistral:latest",
        "description": "Ollama model mistral:latest",
        "memory_required": 0.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    },
    "deepseek-r1:latest": {
        "name": "deepseek-r1:latest",
        "description": "Ollama model deepseek-r1:latest",
        "memory_required": 0.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    },
    "deepseek-coder:latest": {
        "name": "deepseek-coder:latest",
        "description": "Ollama model deepseek-coder:latest",
        "memory_required": 0.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    },
    "codegemma:2b": {
        "name": "codegemma:2b",
        "description": "Ollama model codegemma:2b",
        "memory_required": 1389496506255.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    },
    "gemma:2b": {
        "name": "gemma:2b",
        "description": "Ollama model gemma:2b",
        "memory_required": 0.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    },
    "deepseek-coder-v2:latest": {
        "name": "deepseek-coder-v2:latest",
        "description": "Ollama model deepseek-coder-v2:latest",
        "memory_required": 0.0,
        "parameters": {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_tokens": 1000
        }
    }
}